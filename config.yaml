general_settings:
  store_model_in_db: True
  store_prompts_in_spend_logs: True

model_list:
  - model_name: DeepSeek-R1
    litellm_params:
      model: azure_ai/deepseek-r1
      api_key: os.environ/AZURE_AI_SERVICES_KEY
      api_base: os.environ/AZURE_AI_API_BASE
  - model_name: DeepSeek-V3
    litellm_params:
      model: azure_ai/deepseek-v3
      api_key: os.environ/AZURE_AI_SERVICES_KEY
      api_base: os.environ/AZURE_AI_API_BASE
  - model_name: gpt-image-1-mini
    litellm_params:
      model: azure/gpt-image-1-mini
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
    model_info:
      base_model: azure/gpt-image-1-mini
  - model_name: gpt-image-1
    litellm_params:
      model: azure/gpt-image-1
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
    model_info:
      base_model: azure/gpt-image-1
  - model_name: gpt-4o-mini
    litellm_params:
      model: azure/gpt-4.1-mini
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
    model_info:
      base_model: azure/gpt-4.1-mini
  - model_name: gpt-4o
    litellm_params:
      model: azure/gpt-4.1
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
    model_info:
      base_model: azure/gpt-4.1
  - model_name: o3
    litellm_params:
      model: azure/o3
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
    model_info:
      base_model: azure/o3
  - model_name: gpt-5
    litellm_params:
      model: azure/gpt-5
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
      drop_params: True
      reasoning_effort:
        effort: "minimal"
        summary: "concise"
  - model_name: gpt-5.2
    litellm_params:
      model: azure/gpt-5.2
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
      api_key: os.environ/AZURE_API_KEY
      drop_params: True
      reasoning_effort:
        effort: "minimal"
        summary: "concise"
      # set_verbose: False
      # success_callback: ["langfuse"]
      # cache: True
      # request_timeout: 600
    model_info:
      base_model: azure/gpt-5
  - model_name: gemini-2.5-flash
    litellm_params:
      model: vertex_ai/gemini-2.5-flash
      VERTEXAI_PROJECT: os.environ/VERTEXAI_PROJECT
      VERTEXAI_LOCATION: os.environ/VERTEXAI_LOCATION
      vertex_ai_credentials: os.environ/GOOGLE_APPLICATION_CREDENTIALS
  - model_name: gemini-2.5-flash-image
    litellm_params:
      model: vertex_ai/gemini-2.5-flash-image
      VERTEXAI_PROJECT: os.environ/VERTEXAI_PROJECT
      VERTEXAI_LOCATION: os.environ/VERTEXAI_LOCATION
      vertex_ai_credentials: os.environ/GOOGLE_APPLICATION_CREDENTIALS
  - model_name: gemini-2.5-pro
    litellm_params:
      model: vertex_ai/gemini-2.5-pro
      VERTEXAI_PROJECT: os.environ/VERTEXAI_PROJECT
      VERTEXAI_LOCATION: os.environ/VERTEXAI_LOCATION
      vertex_ai_credentials: os.environ/GOOGLE_APPLICATION_CREDENTIALS
  - model_name: gemini-3-pro-preview
    litellm_params:
      model: vertex_ai/gemini-3-flash-preview
      VERTEXAI_PROJECT: os.environ/VERTEXAI_PROJECT
      VERTEXAI_LOCATION: os.environ/VERTEXAI_LOCATION
      vertex_ai_credentials: os.environ/GOOGLE_APPLICATION_CREDENTIALS
  - model_name: gemini-3-pro-preview
    litellm_params:
      model: vertex_ai/gemini-3-pro-preview
      VERTEXAI_PROJECT: os.environ/VERTEXAI_PROJECT
      VERTEXAI_LOCATION: os.environ/VERTEXAI_LOCATION
      vertex_ai_credentials: os.environ/GOOGLE_APPLICATION_CREDENTIALS
  - model_name: gemini-3-pro-image-preview
    litellm_params:
      model: vertex_ai/gemini-3-pro-image-preview
      VERTEXAI_PROJECT: os.environ/VERTEXAI_PROJECT
      VERTEXAI_LOCATION: os.environ/VERTEXAI_LOCATION
      vertex_ai_credentials: os.environ/GOOGLE_APPLICATION_CREDENTIALS
      # use_in_pass_through: true
      # safety_settings:
      #   - category: HARM_CATEGORY_HARASSMENT
      #     threshold: BLOCK_MEDIUM_AND_ABOVE
      #   - category: HARM_CATEGORY_HATE_SPEECH
      #     threshold: BLOCK_MEDIUM_AND_ABOVE
      #   - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
      #     threshold: BLOCK_MEDIUM_AND_ABOVE
      #   - category: HARM_CATEGORY_DANGEROUS_CONTENT
      #     threshold: BLOCK_MEDIUM_AND_ABOVE
      #   - category: HARM_CATEGORY_UNSPECIFIED
      #     threshold: BLOCK_MEDIUM_AND_ABOVE

litellm_settings:
  json_logs: true # JSON Ê†ºÂºèÊó•Ë™å
  turn_off_message_logging: false # ‰øùÁïôÊ∂àÊÅØÂÖßÂÆπÁî®ÊñºË™øË©¶
  # "HARM_BLOCK_THRESHOLD_UNSPECIFIED", "BLOCK_LOW_AND_ABOVE", "BLOCK_MEDIUM_AND_ABOVE", "BLOCK_ONLY_HIGH", "BLOCK_NONE",
  vertex_ai_safety_settings:
    - category: HARM_CATEGORY_HARASSMENT
      threshold: BLOCK_MEDIUM_AND_ABOVE
    - category: HARM_CATEGORY_HATE_SPEECH
      threshold: BLOCK_MEDIUM_AND_ABOVE
    - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
      threshold: BLOCK_MEDIUM_AND_ABOVE
    - category: HARM_CATEGORY_DANGEROUS_CONTENT
      threshold: BLOCK_MEDIUM_AND_ABOVE
    - category: HARM_CATEGORY_UNSPECIFIED
      threshold: BLOCK_MEDIUM_AND_ABOVE
  default_team_settings:
    - team_id: "default-settings"
      max_budget: 10000.0
      budget_duration: "30d"
      team_member_budget: 1.0
      team_member_rpm_limit: 10
      team_member_tpm_limit: 1000000
  callbacks:
    - prometheus
  prometheus_initialize_budget_metrics: true
  # require_auth_for_metrics_endpoint: true
  prometheus_metrics_config:
    # High-cardinality metrics with minimal labels
    - group: "proxy_metrics"
      metrics:
        - "litellm_proxy_total_requests_metric"
        # - "litellm_proxy_failed_requests_metric"
      include_labels:
        - "hashed_api_key"
        - "requested_model"
        # - "model_group"
    - group: "token_consumption"
      metrics:
        - "litellm_input_tokens_metric"
        - "litellm_output_tokens_metric"
        - "litellm_total_tokens_metric"
      include_labels:
        - "model"
        - "team"
        - "hashed_api_key"
    - group: "request_tracking"
      metrics:
        - "litellm_proxy_total_requests_metric"
      include_labels:
        - "status_code"
        - "requested_model"
    # High-cardinality metrics with minimal labels
    - group: "deployment_health"
      metrics:
        - "litellm_deployment_success_responses"
        - "litellm_deployment_failure_responses"
      include_labels:
        - "api_provider"
        - "requested_model"
    - group: "performance"
      metrics:
        - "litellm_request_total_latency_metric"
        - "litellm_llm_api_latency_metric"
      include_labels:
        - "model"
        - "requested_model"
        # - "api_provider"
    # Budget metrics with full label set
    # - group: "budget_tracking"
    #   metrics:
    #     - "litellm_remaining_team_budget_metric"
    #   include_labels:
    #     - "team"
    #     - "team_alias"
    #     - "hashed_api_key"
    #     - "api_key_alias"
    #     - "model"
    #     - "end_user"
    # Latency metrics with performance-focused labels

guardrails:
  - guardrail_name: "custom-pre-guard"
    litellm_params:
      guardrail: custom_guardrail.myCustomGuardrail # üëà Key change
      mode: "pre_call" # runs async_pre_call_hook
  # - guardrail_name: "custom-during-guard"
  #   litellm_params:
  #     guardrail: custom_guardrail.myCustomGuardrail
  #     mode: "during_call"               # runs async_moderation_hook
  # - guardrail_name: "custom-post-guard"
  #   litellm_params:
  #     guardrail: custom_guardrail.myCustomGuardrail
  #     mode: "post_call"                 # runs async_post_call_success_hook
